#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é˜¶æ®µ 1ï¼šåœ¨æ˜¾å¼å™ªå£°ç¯å¢ƒä¸‹å¯¹ g_phi (MLPFilter) è¿›è¡Œç›‘ç£è®­ç»ƒï¼Œå°†å…¶ä½œä¸ºâ€œå™ªå£°æ£€æµ‹å™¨â€é¢„è®­ç»ƒã€‚

è®¾è®¡è¦ç‚¹ï¼š
- æ•°æ®ï¼šä½¿ç”¨ MT-tgt-split-noise/MT-tgt_*_train_mixï¼ˆclean + D_noise + OODï¼‰ï¼›
- ç›‘ç£æ ‡ç­¾ï¼š
    - è‹¥å›¾åƒæ–‡ä»¶åå±äºåŸå§‹ MT-tgt-split çš„ train å›¾ï¼Œåˆ™è§†ä¸º cleanï¼Œç›®æ ‡æƒé‡ w_i* = 1ï¼›
    - å¦åˆ™è§†ä¸º noise/OODï¼Œç›®æ ‡æƒé‡ w_i* = 0ï¼›
- æ¨¡å‹ï¼š
    - Î¸ï¼šä½¿ç”¨å›ºå®šçš„ YOLO æ£€æµ‹æ¨¡å‹ï¼ˆÎ¸_goodï¼‰ï¼Œä¸æ›´æ–°ï¼›
    - g_phiï¼šMLPFilterï¼Œä»…æ›´æ–° Ï†ï¼›
- è®­ç»ƒç›®æ ‡ï¼š
    - ä½¿ç”¨ PerSampleWeightedDetectionLoss ç”Ÿæˆç‰¹å¾å¹¶å¾—åˆ°å½“å‰ w_iï¼›
    - ä»¥ L_sup = MSE(w_i, w_i*) è®­ç»ƒ g_phiã€‚

è®­ç»ƒå®Œæˆåï¼Œå°† g_phi å‚æ•°ä¿å­˜åˆ°ï¼š
    Toy/Results/Bias+Filter_noise/<scenario>/seed_<seed>/mlpfilter_meta.pt
åç»­å™ªå£°ç‰ˆ Bias+Filter è®­ç»ƒä¼šè‡ªåŠ¨ä»è¯¥è·¯å¾„åŠ è½½ä½œä¸ºåˆå§‹åŒ–ã€‚
"""

from __future__ import annotations

import argparse
import os
from pathlib import Path
from typing import Dict, Any, List, Set

import torch

from ultralytics.models.yolo.detect import DetectionTrainer

BASELINE_ROOT = Path(__file__).resolve().parents[3]  # .../Baseline
ICML_ROOT = BASELINE_ROOT / "ICML"

if str(BASELINE_ROOT) not in __import__("sys").path:
    __import__("sys").path.insert(0, str(BASELINE_ROOT))

from ICML.mt.config import build_bias_finetune_noise_config
from ICML.core.yolo_bias_finetune.train_bias_yolo import build_overrides
from ICML.core.yolo_bias_finetune.anchor import AnchorModel
from ICML.core.yolo_bias_finetune.mlp_filter import MLPFilter, PerSampleWeightedDetectionLoss


def build_clean_name_set(scenario: str) -> Set[str]:
    """æ ¹æ®åœºæ™¯æ„é€  clean å›¾åƒæ–‡ä»¶åé›†åˆï¼Œç”¨äºåŒºåˆ† clean vs noise/OODã€‚"""
    data_root = Path("/root/autodl-tmp/dataset/MT-tgt-split")
    scen_dir = data_root / f"MT-tgt_{scenario}_train" / "images"
    if not scen_dir.exists():
        return set()
    return {p.name for p in scen_dir.glob("*.jpg")}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="é˜¶æ®µ 1ï¼šåœ¨æ˜¾å¼å™ªå£°ç¯å¢ƒä¸‹ç›‘ç£è®­ç»ƒ g_phi (MLPFilter) ä½œä¸ºå™ªå£°æ£€æµ‹å™¨"
    )
    parser.add_argument(
        "--scenarios",
        nargs="*",
        default=["few-shot", "small"],
        help="è¦è¿è¡Œçš„ç›®æ ‡åŸŸåœºæ™¯åˆ—è¡¨ï¼ˆé»˜è®¤ï¼šfew-shot å’Œ smallï¼‰",
    )
    parser.add_argument(
        "--theta-good-seed",
        type=int,
        default=1088,
        help="é€‰æ‹©å“ªä¸ª shared_pretrain seed ä½œä¸º Î¸_good",
    )
    parser.add_argument(
        "--meta-batch-size",
        type=int,
        default=32,
        help="å™ªå£°ç›‘ç£è®­ç»ƒçš„ batch size",
    )
    parser.add_argument(
        "--lr-phi",
        type=float,
        default=1e-3,
        help="MLP FiLTER (g_phi) çš„å­¦ä¹ ç‡",
    )
    return parser.parse_args()


def train_gphi_noise_classifier_for_scenarios(
    scenarios: List[str],
    theta_good_seed: int = 1088,
    meta_batch_size: int = 32,
    lr_phi: float = 1e-3,
) -> None:
    """
    åœ¨ç»™å®šåœºæ™¯åˆ—è¡¨ä¸Šæ‰§è¡Œâ€œè®­ç»ƒ 1â€ï¼šåœ¨å™ªå£°æ··åˆ train ä¸Šç›‘ç£è®­ç»ƒ g_phi ä½œä¸ºå™ªå£°æ£€æµ‹å™¨ã€‚

    ä¾›ä¸€é”®è„šæœ¬ç›´æ¥è°ƒç”¨ï¼Œé¿å…é—æ¼é¢„è®­ç»ƒæ­¥éª¤ã€‚
    """
    cfg = build_bias_finetune_noise_config(
        theta_good_seed=theta_good_seed,
        lambda_bias=1e-4,  # è¿™é‡Œåªéœ€ Î¸_goodï¼ŒÎ» å¯¹ g_phi è®­ç»ƒæ— å½±å“
    )

    valid_scenarios: List[str] = [s for s in scenarios if s in cfg.scenario_data_cfg]
    if not valid_scenarios:
        print("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨åœºæ™¯ï¼ˆfew-shot/smallï¼‰ï¼Œé€€å‡º g_phi å™ªå£°é¢„è®­ç»ƒã€‚")
        return

    for scenario in valid_scenarios:
        data_yaml = cfg.scenario_data_cfg[scenario]
        if not data_yaml.exists():
            print(f"âš ï¸ æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡åœºæ™¯ {scenario}: {data_yaml}")
            continue

        print(
            f"\nğŸ§ª [Train g_phi Noise-Classifier] scenario={scenario}, "
            f"Î¸_good={cfg.theta_good_path}"
        )

        # clean æ–‡ä»¶åé›†åˆï¼Œç”¨äºç”Ÿæˆç›‘ç£æ ‡ç­¾ w_i*
        clean_names = build_clean_name_set(scenario)
        print(f"[INFO] scenario={scenario}, clean image names={len(clean_names)}")

        # ä¸ Bias+Filter_noise è®­ç»ƒä¿æŒè·¯å¾„çº¦å®šä¸€è‡´
        mt_results_root = cfg.results_root.parent  # .../ICML/mt/Results
        bias_filter_noise_root = mt_results_root / "Bias+Filter_noise"

        for seed in cfg.seeds:
            print(f"\n=== åœºæ™¯ {scenario} | ç§å­ {seed} | è®­ç»ƒ g_phi å™ªå£°æ£€æµ‹å™¨ ===")

            # DetectionTrainer ä»…ç”¨äºå¤ç”¨ YOLO dataloader + æ¨¡å‹æ„å»ºé€»è¾‘
            project_dir = (
                bias_filter_noise_root
                / scenario
                / f"seed_{seed}"
                / "gphi_noise_tmp"
            )
            overrides: Dict[str, Any] = build_overrides(
                scenario=scenario,
                training_cfg=cfg.training,
                data_yaml=data_yaml,
                project_dir=project_dir,
                seed=seed,
                model_path=cfg.theta_good_path,  # ä½¿ç”¨ Î¸_good æƒé‡
            )
            overrides["epochs"] = 1
            overrides["batch"] = meta_batch_size
            overrides["workers"] = min(overrides.get("workers", 10), 4)

            trainer = DetectionTrainer(overrides=overrides)
            trainer._setup_train(world_size=0)

            device = trainer.device
            det_model = trainer.model.to(device)
            # å†»ç»“ YOLO å‚æ•°ï¼Œä»…è®­ç»ƒ g_phi
            for p in det_model.parameters():
                p.requires_grad_(False)

            anchor = AnchorModel(cfg.theta_good_path, device=device)
            mlp_filter = MLPFilter(device=device).to(device)
            per_sample_loss = PerSampleWeightedDetectionLoss(
                det_model,
                mlp_filter,
                anchor_model=anchor,
            )

            # ä¼˜åŒ–å™¨åœ¨ç¬¬ä¸€æ¬¡å‰å‘ã€MLPFilter å®Œæˆæ„å»ºä¹‹åå†å»¶è¿Ÿåˆå§‹åŒ–
            opt_phi = None
            train_loader = trainer.train_loader
            if train_loader is None:
                print(f"âš ï¸ train_loader ä¸ºç©ºï¼Œè·³è¿‡åœºæ™¯ {scenario} seed {seed}")
                continue

            # ä½¿ç”¨ä¸ YOLO ç›¸åŒçš„ epoch / patience é…ç½®è¿›è¡Œç›‘ç£è®­ç»ƒ
            max_epochs = cfg.training.get("epochs", 500)
            patience = cfg.training.get("patience", 20)
            best_loss = float("inf")
            best_epoch = -1

            for epoch in range(max_epochs):
                det_model.train()
                running_loss = 0.0
                n_batches = 0
                print(f"[Epoch {epoch + 1}/{max_epochs}]")

                for batch in train_loader:
                    batch = trainer.preprocess_batch(batch)
                    imgs = batch["img"].to(device)

                    # 1) å‰å‘æ„é€  g_phi çš„ w_iï¼ˆé€šè¿‡ PerSampleWeightedDetectionLossï¼‰
                    preds = det_model(imgs)
                    per_sample_loss(preds, batch)  # å¿½ç•¥è¿”å›çš„ detection lossï¼Œåªç”¨ last_weights
                    w = per_sample_loss.last_weights  # (B,)
                    if w is None:
                        continue

                    # 2) æ ¹æ®å›¾åƒæ–‡ä»¶åæ„é€ ç›‘ç£æ ‡ç­¾ w_i*ï¼ˆclean=1, noise/OOD=0ï¼‰
                    im_files = batch.get("im_file") or batch.get("im_files") or batch.get("paths")
                    if im_files is None:
                        continue
                    if isinstance(im_files, (tuple, list)):
                        names = [os.path.basename(str(p)) for p in im_files]
                    else:
                        names = [os.path.basename(str(im_files))]

                    target = torch.zeros_like(w)
                    for i, name in enumerate(names):
                        if name in clean_names:
                            target[i] = 1.0  # clean
                        else:
                            target[i] = 0.0  # noise/OOD

                    # 3) ç›‘ç£æŸå¤±ï¼šMSE(w_i, w_i*)
                    L_sup = torch.mean((w - target.to(w.device)) ** 2)

                    # åœ¨ç¬¬ä¸€æ¬¡æ‹¿åˆ°æœ‰æ•ˆçš„ w_i æ—¶ï¼Œå†æ ¹æ®å®é™…ç‰¹å¾ç»´åº¦æ„å»º MLP head å¹¶åˆ›å»ºä¼˜åŒ–å™¨
                    if opt_phi is None:
                        if not any(p.requires_grad for p in mlp_filter.parameters()):
                            # è‹¥æ­¤æ—¶ä»æ— å¯è®­ç»ƒå‚æ•°ï¼Œè·³è¿‡æœ¬ batch
                            continue
                        opt_phi = torch.optim.Adam(mlp_filter.parameters(), lr=lr_phi)

                    opt_phi.zero_grad()
                    L_sup.backward()
                    opt_phi.step()

                    running_loss += float(L_sup.detach().cpu().item())
                    n_batches += 1

                if n_batches == 0:
                    print("âš ï¸ æœ¬ epoch æ— æœ‰æ•ˆ batchï¼Œæå‰ç»“æŸã€‚")
                    break

                avg_epoch = running_loss / n_batches
                print(f"âœ… Epoch {epoch + 1} å®Œæˆï¼ŒL_sup(avg)={avg_epoch:.4f}")

                # ç®€å• early stopping ç­–ç•¥
                if avg_epoch < best_loss - 1e-4:
                    best_loss = avg_epoch
                    best_epoch = epoch
                elif epoch - best_epoch >= patience:
                    print(
                        f"â¹ï¸ æ—©åœï¼š{epoch - best_epoch} epochs æ— æ”¹è¿› "
                        f"(best={best_loss:.4f} @ epoch {best_epoch + 1})"
                    )
                    break

            # ä¿å­˜ g_phi çš„å‚æ•°åˆ° Bias+Filter_noise/<scenario>/seed_xxx/mlpfilter_meta.pt
            out_dir = bias_filter_noise_root / scenario / f"seed_{seed}"
            out_dir.mkdir(parents=True, exist_ok=True)
            out_path = out_dir / "mlpfilter_meta.pt"
            torch.save(mlp_filter.state_dict(), out_path)
            print(f"ğŸ’¾ å·²ä¿å­˜ g_phi å™ªå£°æ£€æµ‹å™¨å‚æ•°åˆ°: {out_path}")


def main() -> None:
    args = parse_args()
    train_gphi_noise_classifier_for_scenarios(
        scenarios=args.scenarios,
        theta_good_seed=args.theta_good_seed,
        meta_batch_size=args.meta_batch_size,
        lr_phi=args.lr_phi,
    )


if __name__ == "__main__":
    main()
