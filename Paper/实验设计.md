
本章节详细阐述了验证“抗偏差神经滤波器”有效性的实验框架。不同于 Han et al. (2025) 针对无偏估计方差控制的研究，本实验旨在解决**有偏估计 (Biased Estimation)** 下模型崩溃的独特挑战，重点验证在系统性偏差存在时，如何通过**集合感知滤波 (Set-Aware Filtering)** 和 **全局校正 (Global Correction)** 实现鲁棒的递归训练。

---

## 一、 核心论证事实 (Facts to Demonstrate)

我们的实验设计旨在通过实证数据支撑以下四个核心理论推断：

1.  **事实 A：偏差的破坏性 (Destructiveness of Bias)**
    证明在没有干预的情况下，系统性偏差会导致模型崩溃的形式不再是简单的发散，而是收敛错误的“偏移点”或被强力“收缩/拖拽”至退化状态（如 Ridge 下的归零）。
2.  **事实 B：一致最终有界性 (UUB Convergence)**
    证明引入改进后的 Filter 后，模型误差虽然不能像无偏情况那样降为 0，但会**稳定在一个可接受的常数半径 $R^*$ 内**，打破偏差导致的无限漂移或坍塌。
3.  **事实 C：扩张的局限性 (Limits of Scaling)**
    证明单纯增加样本量（Scaling Laws）只能降低方差，**无法消除偏差地板 (Bias Floor)**。而我们的方法能够击穿这个地板，实现比大样本基准更低的误差。
4.  **事实 D：校正机制的主导性 (Dominance of Correction)**
    证明在数据极度稀缺（如 $n=5$）或偏差极强（如强正则化）的极端场景下，单纯的数据加权（Reweighting）失效，必须依靠显式的**全局偏差校正 ($\Delta \phi$)** 来挽救模型。

---

## 二、 实验设置 (Experimental Setup)

### 4.1. 数据生成与递归协议 (Data Generation & Recursive Protocol)

为了精确量化参数漂移，我们采用具有已知真值 $\theta^*$ 的多元高斯分布作为基础生成模型。

*   **真实分布 (Ground Truth):** 数据生成自 $P_{\theta^*} = \mathcal{N}(\mu^*, \Sigma^*)$，其中 $\mu^* = \mathbf{1}_d$（全1向量），$\Sigma^* = \mathbf{I}_d$。基础维度 $d=5$。
*   **递归训练循环 (Recursive Loop):** 模拟 $T=100$ 代的马尔可夫链。
    1.  **第 0 代:** 采样初始数据集 $D_0 \sim P_{\theta^*}$。
    2.  **第 $t$ 代:** 当前模型 $P_{\theta_t}$ 生成候选数据集 $D_t^{cand} = \{x_i\}_{i=1}^{N}$。
    3.  **筛选与更新:** Filter 对 $D_t^{cand}$ 进行处理，输出权重 $w$ 和校正量 $\Delta \phi$，计算参数 $\theta_{t+1}$。
    4.  **迭代:** $P_{\theta_{t+1}}$ 成为下一代的生成器。

### 4.2. 偏差注入机制 (Bias Injection Scenarios)

我们构建了三种场景，涵盖从人工模拟到数学内生的偏差来源：

*   **场景 A：硬编码偏差 (Hard-Coded Bias) - 基准测试**
    显式注入恒定加性误差：$\hat{\theta} = \text{MLE}(D) + \mathbf{b}_{sys}$。
    *   **设置：** 默认 $\mathbf{b}_{sys} = 0.5 \cdot \mathbf{1}_d$。用于受控的敏感性分析。
*   **场景 B：正则化偏差 (Regularization Bias) - 岭回归**
    引入向零收缩的偏差：$\hat{\theta}_{ridge} = \text{argmin} (\|y - X\theta\|^2 + \alpha \|\theta\|^2)$。
    *   **设置：** 正则化系数 $\alpha \in \{1.0, 5.0, 10.0\}$。模拟“为了降方差而牺牲无偏性”的场景。
*   **场景 C：错误先验 (Misspecified Prior) - 贝叶斯估计**
    引入先验拖拽：$\hat{\theta}_{map} \approx \frac{N \bar{x} + \lambda \mu_{prior}}{N + \lambda}$。
    *   **设置：** 真实均值 $\mu^*=5$，先验均值 $\mu_{prior}=0$。样本量 $N$ 对此场景至关重要。

### 4.3. 滤波器模型架构 (Filter Implementation)

采用 **集合感知架构 (Set-Aware Architecture)** 以应对群体性偏差。

*   **输入:** 标准化并 PCA 降维后的特征 $z_i$。
*   **骨干:** 两层 Transformer Encoder Block（或 DeepSets），提取全局上下文。
*   **双头输出:**
    1.  **加权头 (Reweighting):** 输出 $w_i \in [0, 1]$，筛选符合似然的样本。
    2.  **校正头 (Correction):** 输出全局向量 $\Delta \phi \in \mathbb{R}^d$，显式抵消系统性偏差。
*   **训练目标:** $L_{total} = L_{class} + \lambda_1 \|\theta_{new} - \theta_{good}\|_2^2 + \lambda_2 L_{ESS} + \lambda_3 \|\Delta \phi\|_2^2$。

### 4.4. 对照组 (Baselines)

*   **No Filter:** 直接使用有偏估计器训练。
*   **Standard Filter (Han 2025):** 仅含加权头，无校正头，Loss 基于无偏假设。
*   **Ours (Bias-Robust):** 本文提出的双头滤波器。

---

## 三、 具体实验设计 (Key Experiments)

### 实验 1：不同偏差来源下的稳定性验证 (Stability Analysis)
**目的：** 验证 Fact A & B，证明 Filter 能在不同类型的偏差下防止崩溃。

*   **Exp 1.1 (Base):** 硬编码偏差下，对比 $T=100$ 轮的误差曲线。预期 No Filter 线性漂移，Ours 稳定在低位。
*   **Exp 1.2 (Ridge):** 强正则化 ($\alpha=10$) 下。预期 No Filter 参数模长衰减至 0，Ours 维持在真值模长附近。
*   **Exp 1.3 (Prior):** 错误先验 ($\mu_{prior}=0$) 下。预期 No Filter 被吸向 0，Ours 抵抗拖拽，稳定在真值 5 附近。

### 实验 2：对偏差强度与先验误设的敏感性 (Sensitivity)
**目的：** 验证 Fact C，探究 Filter 的鲁棒性边界。

*   **Exp 2.1 (Ridge Sensitivity):** 变化正则系数 $\alpha \in \{1, 10, 50, 100\}$。展示 Filter 如何拓宽 $\alpha$ 的可用范围。
*   **Exp 2.2 (Prior Offset):** 变化先验偏移量 $\delta = \|\mu_{prior} - \mu_{true}\| \in \{0, 5, 10, 20\}$。
    *   *关键图表：* X轴为 $\delta$，Y轴为最终误差。
    *   *预期：* No Filter 呈线性关系（完全受控于先验）；Ours 呈平缓曲线（实现“脱钩”），直到 $\delta$ 极大时才失效。

### 实验 3：样本规模与偏差的对抗 (Scaling Limits & Data Efficiency)
**目的：** 验证 Fact C，反驳单纯的 Scaling Laws，强调校正的重要性。

*   **Exp 3.1 (The Bias Floor):** 硬编码偏差下，对比固定样本量 vs. 二次增长样本量。
    *   *预期：* No Filter 的所有增长策略都收敛到 $\|\mathbf{b}_{sys}\|$ 地板；Ours 即使固定样本量也能击穿地板。
*   **Exp 3.2 (Data Efficiency):** Ridge 设定下，对比 **Small Data ($N=100$) + Ours** 与 **Big Data ($N=10k$) + No Filter**。
    *   *预期：* 两者收敛精度相当，证明 Filter 极大地提升了数据效率。
*   **Exp 3.3 (Extreme Scarcity - The $N=5$ Test):** 贝叶斯设定下，对比 $N=50$ 与 $N=5$。
    *   *预期：* 在 $N=5$ 时，No Filter 瞬间坍塌至先验；Standard Filter 因样本过少无法有效 Reweighting 而失效；**Ours 依靠 $\Delta \phi$ 强行拉回**，证明显式校正在极小样本下的决定性作用。

### 实验 4：机制可解释性 (Interpretability)
**目的：** 验证 Fact D，打开黑盒。

*   **Exp 4.1 (Vector Vis):** 可视化 $\Delta \phi$ 的方向与模长。预期在 Exp 1.1 中收敛至 $-\mathbf{b}_{sys}$，在 Exp 1.2 中随参数 $\theta_t$ 动态变化。
*   **Exp 4.2 (Weight Vis):** 在错误先验实验中，绘制样本值 vs. 权重。预期 Filter 赋予“远离先验均值、靠近似然均值”的样本极高权重（Evidence Selection）。

---

## 四、 需要特别注意的点 (Critical Pitfalls)

在执行上述实验时，需警惕以下陷阱，并在论文中予以说明：

1.  **Reference Estimate ($\theta_{good}$) 的来源悖论**
    *   *风险：* 如果训练 Filter 用的 $\theta_{good}$ 本身就是由有偏估计器生成的，那么 Filter 会学习到错误的“真理”。
    *   *对策：* 实验设置中必须明确声明：我们在 Filter 训练阶段使用了少量“无偏的/人工校准的”数据，或者在仿真实验中使用了上帝视角的真值。这是 Filter 能够“纠偏”的逻辑前提。

2.  **区分“方差缩减”与“偏差消除”**
    *   *风险：* 实验结果混淆了两者。例如 Ridge 回归既有偏差也有方差。
    *   *对策：* 在绘图时，使用 **实线表示平均轨迹（Bias）**，使用 **阴影区域表示标准差（Variance）**。重点展示 Ours 的实线更接近真值，而不仅仅是阴影更窄。

3.  **ESS (Effective Sample Size) 的监控**
    *   *风险：* Filter 为了抵抗偏差，可能把权重极端化（只保留 1 个样本），导致多样性完全丧失（Mode Collapse）。
    *   *对策：* 在报告误差的同时，必须附带报告 ESS 曲线。一个好的 Filter 应该在降低 Bias 的同时，保持 ESS 在一个合理的水平（例如 $>10\%$ 原始样本量）。

4.  **$\Delta \phi$ 的正则化**
    *   *风险：* 在训练初期，网络可能试图用巨大的 $\Delta \phi$ 来解释所有误差，导致训练不稳定。
    *   *对策：* 确保 Loss 中包含适当的 $\|\Delta \phi\|^2$ 正则项，或者在训练初期对 $\Delta \phi$ 进行 Warm-up（逐渐增加其 Learning Rate）。