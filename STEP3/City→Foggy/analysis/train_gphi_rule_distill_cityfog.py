#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Cityâ†’Foggy åœºæ™¯ä¸‹çš„ g_phi è§„åˆ™è’¸é¦è®­ç»ƒè„šæœ¬ï¼ˆRule Distillation for MLPFilterï¼‰ã€‚

ç›®æ ‡ï¼š
- ä½¿ç”¨å›ºå®šçš„ YOLO + L_bias æ£€æµ‹æ¨¡å‹ Î¸ï¼ˆå·²åœ¨ Cityâ†’Foggy ä¸Šå¾®è°ƒå¥½ï¼‰ï¼›
- åˆ©ç”¨ç®€å•ä½†â€œä¸Šå¸è§†è§’â€çš„è§„åˆ™ï¼Œæ ¹æ® z = [loss_box, loss_cls, loss_dfl, conf_diff, iou_diff]
  ç”Ÿæˆæ ·æœ¬çº§ä¼ªæ ‡ç­¾ï¼ˆå¥½æ ·æœ¬=1ï¼Œåæ ·æœ¬=0ï¼‰ï¼›
- åœ¨æ­¤åŸºç¡€ä¸Šç›‘ç£è®­ç»ƒ MLPFilter (g_phi)ï¼Œå¾—åˆ°ä¸€ä¸ªç¨³å®šçš„æ ·æœ¬æƒé‡é¢„æµ‹å™¨ã€‚

æ³¨æ„ï¼š
- è¿™é‡Œåªè®­ç»ƒ g_phiï¼Œä¸æ›´æ–° Î¸ï¼Œä¹Ÿä¸åš meta-learningï¼›
- é˜ˆå€¼é‡‡ç”¨ batch å†…ç™¾åˆ†ä½ (percentile)ï¼Œè€Œä¸æ˜¯å›ºå®šé­”æ³•æ•°å­—ï¼›
- ä¸ä½¿ç”¨ keep-rate æ­£åˆ™ï¼Œé¿å…ä¸ BCE çš„ç›®æ ‡åˆ†å¸ƒå†²çªã€‚
"""

from __future__ import annotations

import argparse
from pathlib import Path
import sys
from typing import Dict, Any, List

import json
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from datetime import datetime

from ultralytics import YOLO
from ultralytics.models.yolo.detect import DetectionTrainer

BASELINE_ROOT = Path(__file__).resolve().parents[3]
if str(BASELINE_ROOT) not in sys.path:
    sys.path.insert(0, str(BASELINE_ROOT))

# å…¼å®¹ PyTorch 2.6 é»˜è®¤ weights_only=Trueï¼šæå‰å…è®¸è‡ªå®šä¹‰ç±»ååºåˆ—åŒ–
try:
    import torch.serialization as _ts
    from ICML.src.yolo_bias_finetune.bias_trainer import BiasWrappedModel

    _ts.add_safe_globals([BiasWrappedModel])
except Exception:
    pass

from ICML.cityfog.config import build_cityfog_bias_finetune_config
from ICML.core.yolo_bias_finetune.anchor import AnchorModel
from ICML.core.yolo_bias_finetune.mlp_filter import MLPFilter, PerSampleWeightedDetectionLoss


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="åœ¨ Cityâ†’Foggy few-shot/small train ä¸Šç”¨è§„åˆ™è’¸é¦è®­ç»ƒ g_phi (MLPFilter)"
    )
    parser.add_argument(
        "--scenarios",
        nargs="+",
        default=["few-shot", "small"],
        help="è¦è®­ç»ƒ g_phi çš„åœºæ™¯åˆ—è¡¨ï¼ˆé»˜è®¤ï¼šfew-shot smallï¼‰",
    )
    parser.add_argument(
        "--theta-good-seed",
        type=int,
        default=1088,
        help="é€‰æ‹©å“ªä¸ª shared_pretrain_city seed ä½œä¸º Î¸_good",
    )
    parser.add_argument(
        "--theta-seed",
        type=int,
        default=None,
        help="é€‰æ‹©å“ªä¸ª CityFog Bias_only seed çš„ Î¸ ä½œä¸ºå›ºå®šæ£€æµ‹æ¨¡å‹ï¼ˆä¸å¡«åˆ™ä½¿ç”¨ --theta-seeds æˆ–é…ç½®é»˜è®¤ seedsï¼‰",
    )
    parser.add_argument(
        "--theta-seeds",
        nargs="+",
        type=int,
        default=None,
        help="ä¸€æ¬¡è®­ç»ƒå¤šä¸ª Î¸ seeds çš„ g_phiï¼ˆé»˜è®¤ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ‰€æœ‰ seedsï¼‰",
    )
    parser.add_argument(
        "--lambda-bias",
        type=float,
        default=1e-4,
        help="å¯¹åº” Bias_only è®­ç»ƒæ—¶ä½¿ç”¨çš„ Î»_biasï¼ˆç”¨äºç¡®å®š Î¸ checkpoint è·¯å¾„ï¼‰",
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=10000,
        help="è§„åˆ™è’¸é¦ g_phi çš„è®­ç»ƒè½®æ•°ï¼ˆéå† train dataloader çš„æ¬¡æ•°ï¼‰",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=64,
        help="è§„åˆ™è’¸é¦é˜¶æ®µçš„ batch size",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="0",
        help="è®­ç»ƒ g_phi ä½¿ç”¨çš„è®¾å¤‡å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ '0'ã€'1' æˆ– 'cpu'",
    )
    parser.add_argument(
        "--keep-rate",
        type=float,
        default=0.95,
        help="è§„åˆ™è’¸é¦æ—¶ä¿ç•™çš„å¥½æ ·æœ¬æ¯”ä¾‹ï¼ˆåŸºäº score çš„ç™¾åˆ†ä½ï¼‰",
    )
    parser.add_argument(
        "--lr-phi",
        type=float,
        default=1e-3,
        help="MLPFilter (g_phi) çš„å­¦ä¹ ç‡",
    )
    parser.add_argument(
        "--patience",
        type=int,
        default=20,
        help="rule distill æ—©åœè€å¿ƒå€¼ï¼ˆæŒ‰ epoch è®¡æ•°ï¼‰",
    )
    parser.add_argument(
        "--min-delta",
        type=float,
        default=0.0,
        help="æ—©åœæ—¶è®¤ä¸ºæœ‰æå‡çš„æœ€å°æ”¹å˜é‡",
    )
    parser.add_argument(
        "--bad-weight",
        type=float,
        default=0.0,
        help="è§„åˆ™è’¸é¦ä¸­åæ ·æœ¬çš„è½¯æ ‡ç­¾æƒé‡ï¼ˆé»˜è®¤ 0.0ï¼Œå¯è®¾ä¸º 0.1 ä»¥é¿å…å®Œå…¨å¤±æ˜ï¼‰",
    )
    parser.add_argument(
        "--floor-weight",
        type=float,
        default=0.3,
        help="å¯¹æ ·æœ¬æƒé‡æ–½åŠ ä¿åº•ï¼ˆSoft Reweightingï¼‰ï¼Œé¿å…æƒé‡è¿‡ä½å¯¼è‡´å¬å›ä¸¢å¤±",
    )
    return parser.parse_args()


class CityFogTrainLoader(DetectionTrainer):
    """
    è½»é‡å°è£… DetectionTrainerï¼Œåªå¤ç”¨å…¶ build_dataset/get_dataloader é€»è¾‘æ„å»º train dataloaderã€‚
    """

    def __init__(self, data_yaml: str, batch_size: int, device: str) -> None:
        # åªä¼ å¿…è¦çš„ overrides
        overrides: Dict[str, Any] = {
            "task": "detect",
            "mode": "train",
            "model": None,  # æˆ‘ä»¬ä¸ä¼šåœ¨è¿™ä¸ª Trainer ä¸­æ„å»ºæ¨¡å‹
            "data": data_yaml,
            "device": device,
            "batch": batch_size,
            "workers": 4,
            "imgsz": 640,
        }
        super().__init__(overrides=overrides)

    def get_model(self, cfg=None, weights=None, verbose=True):
        raise NotImplementedError("CityFogTrainLoader ä¸è´Ÿè´£æ„å»ºæ¨¡å‹")


def build_cityfog_train_loader(data_yaml: str, batch_size: int, device_str: str) -> DataLoader:
    """ä½¿ç”¨ Ultralytics DetectionTrainer æ„å»º Cityâ†’Foggy çš„ train dataloaderã€‚"""
    trainer = CityFogTrainLoader(data_yaml=data_yaml, batch_size=batch_size, device=device_str)
    train_path, _ = trainer.get_dataset()  # è¿”å› train_img_path, val_img_path
    # ç›´æ¥ä½¿ç”¨ trainer.get_dataloaderï¼Œè®©å†…éƒ¨æ­£ç¡®ä¼ é€’ batch_sizeï¼›rank=-1 è¡¨ç¤ºéåˆ†å¸ƒå¼
    train_loader = trainer.get_dataloader(train_path, batch_size=batch_size, rank=-1, mode="train")
    return train_loader


def train_gphi_rule_for_scenario(
    scenario: str,
    theta_good_seed: int,
    theta_seed: int,
    lambda_bias: float,
    epochs: int,
    batch_size: int,
    device_str: str,
    torch_device: torch.device,
    keep_rate: float,
    lr_phi: float,
    patience: int,
    min_delta: float,
    bad_weight: float,
    floor_weight: float,
) -> None:
    """åœ¨æŒ‡å®š CityFog åœºæ™¯ä¸Šæ‰§è¡Œè§„åˆ™è’¸é¦ g_phi è®­ç»ƒã€‚"""
    cfg = build_cityfog_bias_finetune_config(theta_good_seed=theta_good_seed, lambda_bias=lambda_bias)
    if scenario not in cfg.scenario_data_cfg:
        print(f"âš ï¸ æœªçŸ¥åœºæ™¯: {scenario}ï¼Œè·³è¿‡è§„åˆ™è’¸é¦")
        return

    data_yaml = cfg.scenario_data_cfg[scenario]
    if not data_yaml.exists():
        print(f"âš ï¸ æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡åœºæ™¯ {scenario}: {data_yaml}")
        return

    # å›ºå®šæ£€æµ‹æ¨¡å‹ Î¸ï¼šä½¿ç”¨ CityFog Bias_only çš„ best.pt
    lambda_dir = f"lambda_{lambda_bias:g}" if lambda_bias != 0 else "lambda_0"
    theta_ckpt = (
        BASELINE_ROOT
        / "ICML"
        / "Cityâ†’Foggy"
        / "Results"
        / "Bias_only"
        / lambda_dir
        / scenario
        / f"seed_{theta_seed}"
        / "results"
        / "weights"
        / "best.pt"
    )
    if not theta_ckpt.exists():
        print(f"âš ï¸ æœªæ‰¾åˆ° CityFog Bias_only Î¸ checkpoint: {theta_ckpt}ï¼Œè·³è¿‡åœºæ™¯ {scenario}")
        return

    print(f"\nğŸ§ª [Rule Distill g_phi] scenario={scenario}, Î¸_good_seed={theta_good_seed}, Î¸_seed={theta_seed}")
    print(f"    data_yaml = {data_yaml}")
    print(f"    Î¸ (Bias_only) = {theta_ckpt}")

    # æ„å»ºå›ºå®šæ£€æµ‹æ¨¡å‹å’Œé”šç‚¹ AnchorModel
    yolo = YOLO(str(theta_ckpt))
    det_model = yolo.model
    # è‹¥ checkpoint ä¸­ä¿å­˜çš„æ˜¯ BiasWrappedModelï¼Œåˆ™è§£åŒ…å‡ºå†…éƒ¨çš„ DetectionModel
    if hasattr(det_model, "inner"):
        det_model = det_model.inner
    det_model = det_model.to(torch_device).eval()

    anchor = AnchorModel(cfg.theta_good_path, device=torch_device)

    # ç‹¬ç«‹çš„ MLPFilter (g_phi) ç”¨äºè§„åˆ™è’¸é¦è®­ç»ƒ
    # æ­¤å¤„ç‰¹å¾ç»´åº¦å›ºå®šä¸º 5: [loss_box, loss_cls, loss_dfl, conf_diff, iou_diff]
    g_phi = MLPFilter(input_dim=5, device=torch_device)
    g_phi.to(torch_device)

    # PerSampleWeightedDetectionLoss åªç”¨äºäº§å‡º z ç‰¹å¾ï¼ˆä¸åœ¨å…¶ä¸­ä½¿ç”¨ MLP æƒé‡ï¼‰
    per_sample_loss = PerSampleWeightedDetectionLoss(
        model=det_model,
        sample_filter=None,
        anchor_model=anchor,
        filter_mode="mlp",  # ä»æŒ‰ mlp åˆ†æ”¯æ„é€  z = [loss_box, loss_cls, loss_dfl, conf_diff, iou_diff]
    )

    optimizer_phi = torch.optim.Adam(g_phi.parameters(), lr=lr_phi)
    bce = nn.BCELoss()

    # æ„å»º CityFog train dataloader
    train_loader = build_cityfog_train_loader(str(data_yaml), batch_size=batch_size, device_str=device_str)

    best_loss = float("inf")
    best_state = None
    wait = 0

    for epoch in range(epochs):
        running_loss = 0.0
        total_samples = 0
        print(f"\n=== [Rule Distill g_phi] Epoch {epoch + 1}/{epochs} ({scenario}) ===")

        for step, batch in enumerate(train_loader, start=1):
            imgs = batch["img"].to(torch_device, non_blocking=True).float()
            batch = {k: (v.to(torch_device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}
            batch["img"] = imgs

            # 1) å›ºå®š Î¸ å’Œ Anchorï¼Œæå– per-sample ç‰¹å¾ zï¼ˆä¸éœ€è¦å¯¹ Î¸ æ±‚æ¢¯åº¦ï¼‰
            with torch.no_grad():
                preds = det_model(batch["img"])
                _, _, features = per_sample_loss(preds, batch, return_features=True)  # (B, 5)

            # ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆæ‰¹å†…ï¼‰ï¼šz_norm
            mean = features.mean(dim=0, keepdim=True)
            std = features.std(dim=0, keepdim=True).clamp(min=1e-6)
            z_norm = (features - mean) / std  # (B, 5)

            loss_box = z_norm[:, 0]
            loss_cls = z_norm[:, 1]
            loss_dfl = z_norm[:, 2]
            conf_diff = z_norm[:, 3]
            iou_diff = z_norm[:, 4]

            # 2) è§„åˆ™å®šä¹‰åæ ·æœ¬ï¼šåŸºäº score çš„ç™¾åˆ†ä½
            # ç¤ºä¾‹ï¼šscore = 0.5 * conf_diff + 0.5 * loss_cls
            score = 0.5 * conf_diff + 0.5 * loss_cls
            B = score.shape[0]
            keep = float(keep_rate)
            keep = min(max(keep, 0.0), 1.0)
            k = max(int(keep * B) - 1, 0)
            sorted_score, _ = torch.sort(score)
            thr = sorted_score[k]
            is_bad = score > thr

            # Soft reweightingï¼šä¸ºåæ ·æœ¬è®¾ç½®ä¿åº•æƒé‡ï¼Œé¿å…å®Œå…¨â€œå¤±æ˜â€
            floor_w = float(floor_weight)
            floor_w = min(max(floor_w, 0.0), 1.0)
            bad_w = float(bad_weight)
            bad_w = max(min(bad_w, 1.0), 0.0)
            bad_w = max(bad_w, floor_w)
            target_weights = torch.where(is_bad, bad_w, 1.0).float().view(-1, 1)  # (B,1)
            target_weights = torch.clamp(target_weights, min=floor_w, max=1.0)

            # 3) è®­ç»ƒ g_phiï¼šç›‘ç£å­¦ä¹  w_i â‰ˆ target_weights
            optimizer_phi.zero_grad()
            pred_weights = g_phi(z_norm)  # (B,1)
            pred_weights = torch.clamp(pred_weights, min=floor_w, max=1.0)

            loss_cheat = bce(pred_weights, target_weights)
            loss_cheat.backward()
            optimizer_phi.step()

            running_loss += float(loss_cheat.detach().cpu().item()) * B
            total_samples += B

            if step % 20 == 0:
                avg = running_loss / max(total_samples, 1)
                print(f"  [step {step}] rule_distill_loss={avg:.4f}")

        epoch_avg = running_loss / max(total_samples, 1)
        print(f"âœ… Epoch {epoch + 1} å®Œæˆï¼Œå¹³å‡ rule_distill_loss={epoch_avg:.4f}")

        if epoch_avg + min_delta < best_loss:
            best_loss = epoch_avg
            best_state = {k: v.detach().cpu().clone() for k, v in g_phi.state_dict().items()}
            wait = 0
        else:
            wait += 1
            if wait >= patience:
                print(f"â¹ï¸ æ—©åœï¼šè¿ç»­ {patience} ä¸ª epoch æ— æ˜æ˜¾æ”¹è¿›ï¼ˆbest_loss={best_loss:.4f}ï¼‰")
                break

    # ä¿å­˜ g_phi å‚æ•°
    out_dir = (
        BASELINE_ROOT
        / "ICML"
        / "Cityâ†’Foggy"
        / "Results"
        / "Bias+Filter_rule"
        / f"lambda_{lambda_bias:g}"
        / scenario
        / f"seed_{theta_seed}"
    )
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "mlpfilter_rule.pt"
    state_to_save = best_state if best_state is not None else g_phi.state_dict()
    torch.save(state_to_save, out_path)
    # è®°å½•æœ¬æ¬¡è§„åˆ™è’¸é¦çš„å…³é”®å‚æ•°ï¼Œä¾¿äºåç»­æº¯æº
    meta = {
        "scenario": scenario,
        "theta_good_seed": theta_good_seed,
        "theta_seed": theta_seed,
        "lambda_bias": lambda_bias,
        "epochs": epochs,
        "batch_size": batch_size,
        "device": str(device_str),
        "keep_rate": keep_rate,
        "lr_phi": lr_phi,
        "patience": patience,
        "min_delta": min_delta,
        "bad_weight": bad_weight,
        "floor_weight": floor_weight,
        "best_rule_distill_loss": best_loss if best_loss != float('inf') else None,
        "timestamp": datetime.now().isoformat(),
    }
    meta_path = out_dir / "rule_train_meta.json"
    with meta_path.open("w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ å·²ä¿å­˜è§„åˆ™è’¸é¦åçš„ g_phi å‚æ•°åˆ°: {out_path}")


def main() -> None:
    args = parse_args()

    base_cfg = build_cityfog_bias_finetune_config(theta_good_seed=args.theta_good_seed, lambda_bias=args.lambda_bias)

    # é»˜è®¤è·‘é…ç½®é‡Œçš„ä¸‰ä¸ª seedsï¼›è‹¥æ˜¾å¼æŒ‡å®šåˆ™æŒ‰ç”¨æˆ·è¾“å…¥è¦†ç›–
    if args.theta_seeds is not None:
        theta_seeds: List[int] = args.theta_seeds
    elif args.theta_seed is not None:
        theta_seeds = [args.theta_seed]
    else:
        theta_seeds = base_cfg.seeds

    device_str = args.device
    if device_str.lower() == "cpu":
        torch_device = torch.device("cpu")
    elif device_str.isdigit():
        torch_device = torch.device(f"cuda:{device_str}")
    else:
        torch_device = torch.device(device_str)

    scenarios: List[str] = args.scenarios

    for scenario in scenarios:
        for theta_seed in theta_seeds:
            train_gphi_rule_for_scenario(
                scenario=scenario,
                theta_good_seed=args.theta_good_seed,
                theta_seed=theta_seed,
                lambda_bias=args.lambda_bias,
                epochs=args.epochs,
                batch_size=args.batch_size,
                device_str=device_str,
                torch_device=torch_device,
                keep_rate=args.keep_rate,
                lr_phi=args.lr_phi,
                patience=args.patience,
                min_delta=args.min_delta,
                bad_weight=args.bad_weight,
                floor_weight=args.floor_weight,
            )


if __name__ == "__main__":
    main()
